# SoftHelp Support API
# SoftHelp Inc.
Ejemplo FastAPI
# ü§ñ API de Soporte Inteligente Multimodal

Esta es una API REST multimodal dise√±ada para actuar como un sistema de soporte t√©cnico inteligente para SoftHelp Inc. La API puede recibir preguntas de usuarios en formato de texto, audio o imagen, procesarlas utilizando un stack de modelos de IA de c√≥digo abierto, y devolver una respuesta tanto en texto como en audio sintetizado.

El sistema utiliza una arquitectura **RAG (Retrieval-Augmented Generation)** para basar sus respuestas en una base de conocimiento interna (manuales, FAQs, etc.).

---

## ‚ú® Caracter√≠sticas Principales

* **Entrada Multimodal:** Acepta peticiones con texto, audio (`.mp3`, `.wav`) e im√°genes (`.jpg`, `.png`).
* **Speech-to-Text:** Transcripci√≥n de audio de alta precisi√≥n utilizando **Whisper**.
* **An√°lisis de Visi√≥n:** Descripci√≥n de im√°genes y capturas de pantalla mediante el modelo **LLaVA**.
* **Generaci√≥n Aumentada por Recuperaci√≥n (RAG):** B√∫squeda de contexto en una base de conocimiento vectorial (ChromaDB) para respuestas m√°s precisas y fundamentadas.
* **Generaci√≥n de Lenguaje Natural:** Creaci√≥n de respuestas t√©cnicas claras utilizando un LLM local como **Phi-3**.
* **Text-to-Speech:** Conversi√≥n de la respuesta de texto a voz utilizando **gTTS**.
* **API Robusta:** Construida con **FastAPI**, garantizando alto rendimiento y una documentaci√≥n interactiva autom√°tica.
* **100% Open Source:** Todo el stack de IA puede correr localmente utilizando **Ollama**.
* **Prompt aumentado:** Crea un prompt aumentado y configurado para generar la respuesta m√°s acertada basado en su contexto **RAG**.

---

## üõ†Ô∏è Stack Tecnol√≥gico

| Componente | Herramienta |
| :--- | :--- |
| **Framework API** | `FastAPI` |
| **Servidor** | `Uvicorn` |
| **Servidor de Modelos IA** | `Ollama` |
| **LLM de Texto** | `Phi-3` (o `Llama 3`) |
| **LLM de Visi√≥n (V2V)**| `LLaVA` |
| **Transcripci√≥n (STT)**| `Whisper` (OpenAI) |
| **S√≠ntesis de Voz (TTS)**| `gTTS` |
| **Orquestador RAG** | `LangChain` |
| **Base de Datos Vectorial** | `ChromaDB` |
| **Embeddings** | `SentenceTransformers` |

---

## ‚öôÔ∏è Configuraci√≥n e Instalaci√≥n

### Requisitos Previos

Aseg√∫rate de tener instalado lo siguiente en tu sistema:

1.  **Python 3.8+** y `pip`.
2.  **Ollama:** Sigue la [gu√≠a de instalaci√≥n oficial](https://ollama.com/).
3.  **ffmpeg:** Herramienta esencial para el procesamiento de audio.
    * **Windows (con Chocolatey):** `choco install ffmpeg`
    * **macOS (con Homebrew):** `brew install ffmpeg`
    * **Linux (con apt):** `sudo apt update && sudo apt install ffmpeg`

### Pasos de Instalaci√≥n

1.  **Clona el repositorio (si aplica):**
    ```bash
    git clone [https://tu-repositorio.git](https://tu-repositorio.git)
    cd nombre-del-proyecto
    ```

2.  **Crea y activa un entorno virtual:**
    ```bash
    python -m venv .venv
    # En Windows
    .venv\Scripts\activate
    # En macOS/Linux
    source .venv/bin/activate
    ```

3.  **Instala las dependencias de Python:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Descarga los modelos de Ollama:**
    ```bash
    ollama pull phi3
    ollama pull llava
    ```

5.  **Prepara la Base de Conocimiento:**
    * Crea una carpeta llamada `knowledge_base` en la ra√≠z del proyecto.
    * Coloca dentro tus archivos `.pdf` y `.txt` (ej: `Manual_Usuario.pdf`, `FAQ.txt`).

---

## ‚ñ∂Ô∏è Ejecuci√≥n de la Aplicaci√≥n

1.  **Ingesta de Datos (Ejecutar solo una vez o al cambiar los documentos):**
    Este script procesar√° los documentos de `knowledge_base/` y los guardar√° en la base de datos vectorial.
    ```bash
    python ingest.py
    ```

2.  **Inicia el Servidor de la API:**
    Aseg√∫rate de que la aplicaci√≥n de Ollama est√© corriendo en tu sistema. Luego, ejecuta:
    ```bash
    uvicorn app.main:app --reload
    ```
    La API estar√° disponible en `http://localhost:8000`.

---

## üìö Documentaci√≥n de la API

Una vez que el servidor est√© en marcha, puedes acceder a la documentaci√≥n interactiva (generada por Swagger UI) en la siguiente URL para probar los endpoints directamente desde tu navegador:

üîó **http://localhost:8000/docs**

### Endpoints Disponibles

| M√©todo | Endpoint | Descripci√≥n | Cuerpo de la Petici√≥n (form-data) |
| :--- | :--- | :--- | :--- |
| `POST` | `/support` | Env√≠a una pregunta por texto y una imagen opcional. | `text_query` (string), `image` (file) |
| `POST` | `/support/audio` | Env√≠a una pregunta por audio y una imagen opcional. | `audio` (file), `image` (file) |
| `GET`  | `/` | Endpoint de bienvenida ||

### Ejemplo de Uso con `curl`

```bash
curl -X POST "http://localhost:8000/support/audio" \
-F "audio=@/ruta/a/tu/pregunta.mp3" \
-F "image=@/ruta/a/tu/captura.png"
